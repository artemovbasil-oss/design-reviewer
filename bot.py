# bot.py ‚Äî Design Review Partner (aiogram 3.7.0)
# - ASCII –ø—Ä–æ–≥—Ä–µ—Å—Å —Å fallback (–µ—Å–ª–∏ edit –Ω–µ–ª—å–∑—è, —Å–æ–∑–¥–∞—ë–º 1 –Ω–æ–≤—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å-–º–µ—Å—Å–µ–¥–∂ –∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º –µ–≥–æ)
# - Hybrid: OCR (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω) -> –∏–Ω–∞—á–µ LLM "extract"
# - 3 –∏—Ç–æ–≥–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏—è: —á—Ç–æ –≤–∏–∂—É / –≤–∏–∑—É–∞–ª (–æ—Ü–µ–Ω–∫–∞) / —Ç–µ–∫—Å—Ç—ã
# - –ë–µ–∑ —Ç–µ—Ö. –¥–µ—Ç–∞–ª–µ–π (px/—Ü–≤–µ—Ç-–∫–æ–¥—ã), —à—Ä–∏—Ñ—Ç—ã/–ø–∞–ª–∏—Ç—Ä–∞ ‚Äî —Ç–æ–ª—å–∫–æ –¥–æ–≥–∞–¥–∫–∏

import os
import re
import json
import base64
import asyncio
from io import BytesIO
from pathlib import Path
from typing import Dict, Any, Optional, List

from PIL import Image

from aiogram import Bot, Dispatcher, F
from aiogram.types import Message, KeyboardButton, ReplyKeyboardMarkup
from aiogram.client.default import DefaultBotProperties
from aiogram.enums import ParseMode
from aiogram.exceptions import TelegramBadRequest

from openai import OpenAI

# OCR (optional)
try:
    import pytesseract  # type: ignore
    OCR_PY_AVAILABLE = True
except Exception:
    OCR_PY_AVAILABLE = False

# optional OpenCV for better OCR
try:
    import cv2  # type: ignore
    import numpy as np  # type: ignore
    CV_AVAILABLE = True
except Exception:
    CV_AVAILABLE = False


# =============================
# Local .env loader (no python-dotenv)
# =============================
def load_local_env_file() -> None:
    env_path = Path(__file__).with_name(".env")
    if not env_path.exists():
        return
    try:
        for line in env_path.read_text(encoding="utf-8").splitlines():
            line = line.strip()
            if not line or line.startswith("#") or "=" not in line:
                continue
            k, v = line.split("=", 1)
            k = k.strip()
            v = v.strip().strip('"').strip("'")
            os.environ.setdefault(k, v)
    except Exception:
        pass


load_local_env_file()

BOT_TOKEN = os.getenv("BOT_TOKEN", "").strip()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()
LLM_MODEL = os.getenv("LLM_MODEL", "gpt-4o-mini").strip()
OCR_LANG = os.getenv("OCR_LANG", "rus+eng").strip()

if not BOT_TOKEN:
    raise RuntimeError("BOT_TOKEN is not set (Railway Variables or local .env)")
if not OPENAI_API_KEY:
    raise RuntimeError("OPENAI_API_KEY is not set (Railway Variables or local .env)")

client = OpenAI(api_key=OPENAI_API_KEY)

# =============================
# Telegram UI
# =============================
BTN_SEND = "üñº –ó–∞–∫–∏–Ω—É—Ç—å —Å–∫—Ä–∏–Ω"
BTN_HELP = "‚ÑπÔ∏è –ö–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è"
BTN_PING = "üèì Ping"

keyboard = ReplyKeyboardMarkup(
    keyboard=[
        [KeyboardButton(text=BTN_SEND)],
        [KeyboardButton(text=BTN_HELP), KeyboardButton(text=BTN_PING)],
    ],
    resize_keyboard=True,
    input_field_placeholder="–ö–∏–¥–∞–π —Å–∫—Ä–∏–Ω ‚Äî —è —Ä–∞–∑–±–µ—Ä—É –µ–≥–æ –ø–æ-–≤–∑—Ä–æ—Å–ª–æ–º—É.",
)

bot = Bot(
    token=BOT_TOKEN,
    default=DefaultBotProperties(parse_mode=ParseMode.HTML),
)
dp = Dispatcher()

# per-chat lock (—á—Ç–æ–±—ã –ø—Ä–æ–≥—Ä–µ—Å—Å/–æ—Ç–≤–µ—Ç—ã –Ω–µ –ø—É—Ç–∞–ª–∏—Å—å)
_CHAT_LOCKS: Dict[int, asyncio.Lock] = {}


def get_chat_lock(chat_id: int) -> asyncio.Lock:
    lock = _CHAT_LOCKS.get(chat_id)
    if lock is None:
        lock = asyncio.Lock()
        _CHAT_LOCKS[chat_id] = lock
    return lock


# =============================
# Helpers
# =============================
def html_escape(text: str) -> str:
    return (
        text.replace("&", "&amp;")
        .replace("<", "&lt;")
        .replace(">", "&gt;")
    )


def clamp_score(x: Any) -> int:
    try:
        n = int(x)
    except Exception:
        n = 6
    return max(1, min(10, n))


def img_to_base64_png(image: Image.Image) -> str:
    buf = BytesIO()
    image.save(buf, format="PNG")
    return base64.b64encode(buf.getvalue()).decode("utf-8")


def ascii_bar(i: int) -> str:
    frames = [
        "‚ñ±‚ñ±‚ñ±‚ñ±‚ñ±",
        "‚ñ∞‚ñ±‚ñ±‚ñ±‚ñ±",
        "‚ñ∞‚ñ∞‚ñ±‚ñ±‚ñ±",
        "‚ñ∞‚ñ∞‚ñ∞‚ñ±‚ñ±",
        "‚ñ∞‚ñ∞‚ñ∞‚ñ∞‚ñ±",
        "‚ñ∞‚ñ∞‚ñ∞‚ñ∞‚ñ∞",
        "‚ñ∞‚ñ∞‚ñ∞‚ñ∞‚ñ∞‚úì",
    ]
    return frames[max(0, min(i, len(frames) - 1))]


def spinner(i: int) -> str:
    return ["|", "/", "‚Äî", "\\"][i % 4]


def parse_llm_json(raw: str) -> Optional[Dict[str, Any]]:
    raw = raw.strip()
    m = re.search(r"\{.*\}", raw, flags=re.S)
    if not m:
        return None
    try:
        return json.loads(m.group(0))
    except Exception:
        return None


# =============================
# Progress animation (no-spam but always visible)
# =============================
async def safe_edit_text_or_recreate(msg: Message, text: str) -> Message:
    """
    –ü—ã—Ç–∞–µ–º—Å—è –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å msg.
    –ï—Å–ª–∏ Telegram –Ω–µ –¥–∞—ë—Ç —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å (message can't be edited) ‚Äî
    —Å–æ–∑–¥–∞—ë–º –û–î–ù–û –Ω–æ–≤–æ–µ –ø—Ä–æ–≥—Ä–µ—Å—Å-—Å–æ–æ–±—â–µ–Ω–∏–µ –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –Ω–∞ –Ω—ë–º.
    """
    try:
        await msg.edit_text(text)
        return msg
    except TelegramBadRequest:
        try:
            new_msg = await msg.answer(text)
            return new_msg
        except TelegramBadRequest:
            return msg


async def animate_progress(msg: Message, title: str = "üîç –°–º–æ—Ç—Ä—é –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ‚Ä¶") -> Message:
    current = msg
    for i in range(10):
        bar = ascii_bar(min(i, 6))
        frame = f"{title} {spinner(i)}\n<pre>{bar}</pre>"
        current = await safe_edit_text_or_recreate(current, frame)
        await asyncio.sleep(0.22)
    return current


async def set_progress(msg: Message, title: str, step: int) -> Message:
    bar = ascii_bar(step)
    frame = f"{title} {spinner(step)}\n<pre>{bar}</pre>"
    return await safe_edit_text_or_recreate(msg, frame)


# =============================
# OCR pipeline (best effort)
# =============================
def preprocess_for_ocr(pil: Image.Image) -> Image.Image:
    if not CV_AVAILABLE:
        return pil.convert("RGB")

    img = np.array(pil.convert("RGB"))
    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    gray = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)
    thr = cv2.adaptiveThreshold(
        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 8
    )
    return Image.fromarray(thr)


def ocr_extract(pil: Image.Image) -> Dict[str, Any]:
    """
    Returns:
    {
      ok: bool,
      text: str,
      blocks: [ {text, kind_guess} ... ]  # bbox intentionally removed for simplicity
    }
    """
    if not OCR_PY_AVAILABLE:
        return {"ok": False, "reason": "pytesseract not installed", "text": "", "blocks": []}

    try:
        img = preprocess_for_ocr(pil)
        data = pytesseract.image_to_data(img, lang=OCR_LANG, output_type=pytesseract.Output.DICT)
    except Exception as e:
        # Most common on Railway: tesseract binary missing
        return {"ok": False, "reason": f"tesseract error: {e}", "text": "", "blocks": []}

    n = len(data.get("text", []))
    lines: Dict[str, List[str]] = {}
    full_words: List[str] = []

    for i in range(n):
        txt = (data["text"][i] or "").strip()
        if not txt:
            continue
        conf = -1.0
        try:
            conf = float(data.get("conf", ["-1"])[i])
        except Exception:
            pass
        if conf >= 0 and conf < 35:
            continue

        full_words.append(txt)
        key = f"{data.get('block_num',[0])[i]}:{data.get('par_num',[0])[i]}:{data.get('line_num',[0])[i]}"
        lines.setdefault(key, []).append(txt)

    blocks = []
    for _, words in lines.items():
        line = " ".join(words).strip()
        if not line:
            continue
        # Very rough guess
        kind = "text"
        if len(line) <= 20:
            kind = "title_or_button"
        if len(line) <= 14:
            kind = "button_like"
        blocks.append({"text": line, "kind_guess": kind})

    return {"ok": True, "text": " ".join(full_words).strip(), "blocks": blocks}


# =============================
# LLM: extract (fallback when OCR fails)
# =============================
def llm_extract_text_structure(image_b64: str) -> Dict[str, Any]:
    """
    Fallback when OCR isn't available: ask LLM to extract text blocks.
    Returns:
      { ok: bool, text: str, blocks: [{text, kind_guess}] }
    """
    prompt = """
–¢—ã –≤–∏–¥–∏—à—å —Å–∫—Ä–∏–Ω –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –≤—ã—Ç–∞—â–∏—Ç—å —Ç–µ–∫—Å—Ç –∏ –ø–æ–Ω—è—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É.
–í–µ—Ä–Ω–∏ –°–¢–†–û–ì–û JSON:
{
  "text": "–≤–µ—Å—å —Ç–µ–∫—Å—Ç –Ω–∞ —ç–∫—Ä–∞–Ω–µ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π (–µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –Ω–µ —á–∏—Ç–∞–µ—Ç—Å—è ‚Äî –ø—Ä–æ–ø—É—Å—Ç–∏)",
  "blocks": [
    {"text":"...", "kind_guess":"title_or_button|button_like|text|hint|status"},
    ...
  ]
}
–ë–µ–∑ –ª–∏—à–Ω–∏—Ö –∫–ª—é—á–µ–π. –ë–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π. –¢–æ–ª—å–∫–æ JSON.
"""
    resp = client.responses.create(
        model=LLM_MODEL,
        input=[
            {
                "role": "user",
                "content": [
                    {"type": "input_text", "text": prompt},
                    {"type": "input_image", "image_base64": image_b64},
                ],
            }
        ],
        max_output_tokens=700,
    )

    out_text = ""
    for item in getattr(resp, "output", []) or []:
        for c in item.content or []:
            if getattr(c, "type", None) == "output_text":
                out_text += getattr(c, "text", "") + "\n"

    data = parse_llm_json(out_text.strip())
    if not data:
        return {"ok": False, "text": "", "blocks": []}

    text = str(data.get("text", "")).strip()
    blocks = data.get("blocks", [])
    if not isinstance(blocks, list):
        blocks = []
    cleaned = []
    for b in blocks[:80]:
        if not isinstance(b, dict):
            continue
        t = str(b.get("text", "")).strip()
        if not t:
            continue
        k = str(b.get("kind_guess", "text")).strip()
        cleaned.append({"text": t, "kind_guess": k})

    return {"ok": True, "text": text, "blocks": cleaned}


# =============================
# LLM: review (image + extracted text)
# =============================
def analyze_ui_with_openai(image_b64: str, extracted: Dict[str, Any]) -> Dict[str, Any]:
    ocr_text = (extracted.get("text") or "").strip()
    blocks = extracted.get("blocks") or []
    blocks_short = blocks[:80]

    prompt = f"""
–¢—ã ‚Äî —Å—Ç–∞—Ä—à–∏–π –ø—Ä–æ–¥—É–∫—Ç–æ–≤—ã–π –¥–∏–∑–∞–π–Ω–µ—Ä –∏ —Ç—Ä–µ–±–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –¥–∏–∑–∞–π–Ω-—Ä–µ–≤—å—é–µ—Ä.
–ì–æ–≤–æ—Ä–∏—à—å –ø–æ-—Ä—É—Å—Å–∫–∏. –ë–µ–∑ –º–∞—Ç–∞. –ë–µ–∑ —Å—é—Å—é–∫–∞–Ω—å—è.
–ï—Å–ª–∏ —Ö–æ—Ä–æ—à–æ ‚Äî —Ö–≤–∞–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ. –ï—Å–ª–∏ –ø–ª–æ—Ö–æ ‚Äî —Ä—É–≥–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–π —É–ª—É—á—à–µ–Ω–∏—è.

–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:
- –ù–∏–∫–∞–∫–∏—Ö —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π (–ø–∏–∫—Å–µ–ª–∏, –∫–æ–¥—ã —Ü–≤–µ—Ç–æ–≤, —Ä–∞—Å—á—ë—Ç—ã).
- –ü—Ä–æ —à—Ä–∏—Ñ—Ç/–ø–∞–ª–∏—Ç—Ä—É ‚Äî —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏—è ("–ø–æ—Ö–æ–∂–µ –Ω–∞ sans-serif —Ç–∏–ø–∞ Inter/SF/Roboto").
- –ù–µ –ø—É—Ç–∞–π –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ –∫–Ω–æ–ø–∫–∏. –°–≤–µ—Ä—è–π—Å—è —Å –∫–∞—Ä—Ç–∏–Ω–∫–æ–π –∏ –±–ª–æ–∫–∞–º–∏ —Ç–µ–∫—Å—Ç–∞.
- –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π —ç–ª–µ–º–µ–Ω—Ç—ã.

–ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:
{ocr_text[:2000]}

–ë–ª–æ–∫–∏ (—Å—Ç—Ä–æ–∫–∏) —Å –≥—Ä—É–±—ã–º guess:
{json.dumps(blocks_short, ensure_ascii=False)}

–í–µ—Ä–Ω–∏ –°–¢–†–û–ì–û JSON:
{{
  "description": "2‚Äì6 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–∞ —ç–∫—Ä–∞–Ω–µ",
  "score": 1-10,
  "visual": "5‚Äì12 –ø—É–Ω–∫—Ç–æ–≤: –≤–∏–∑—É–∞–ª/UX (—Å –ø–æ—Ö–≤–∞–ª–æ–π, –µ—Å–ª–∏ –µ—Å—Ç—å)",
  "text": "6‚Äì14 –ø—É–Ω–∫—Ç–æ–≤: —Ç–µ–∫—Å—Ç (–∫–∞–∂–¥—ã–π –ø—É–Ω–∫—Ç: –ü—Ä–æ–±–ª–µ–º–∞ ‚Üí –ü–æ—á–µ–º—É –ø–ª–æ—Ö–æ ‚Üí –ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å)"
}}
"""

    resp = client.responses.create(
        model=LLM_MODEL,
        input=[
            {
                "role": "user",
                "content": [
                    {"type": "input_text", "text": prompt},
                    {"type": "input_image", "image_base64": image_b64},
                ],
            }
        ],
        max_output_tokens=950,
    )

    out_text = ""
    for item in getattr(resp, "output", []) or []:
        for c in item.content or []:
            if getattr(c, "type", None) == "output_text":
                out_text += getattr(c, "text", "") + "\n"

    out_text = out_text.strip()
    data = parse_llm_json(out_text)
    if not data:
        # fallback: plain text without dict junk
        return {
            "description": (out_text[:900] or "–ù–µ —Å–º–æ–≥ —Å–æ–±—Ä–∞—Ç—å –æ—Ç—á—ë—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏."),
            "score": 5,
            "visual": "‚Äî",
            "text": "‚Äî",
        }

    return {
        "description": str(data.get("description", "")).strip(),
        "score": clamp_score(data.get("score", 6)),
        "visual": str(data.get("visual", "")).strip(),
        "text": str(data.get("text", "")).strip(),
    }


# =============================
# Handlers
# =============================
@dp.message(F.text.in_({"/start", "start"}))
async def start(m: Message):
    await m.answer(
        "üëã –Ø ‚Äî —Ç–≤–æ–π <b>–ø–∞—Ä—Ç–Ω—ë—Ä –ø–æ –¥–∏–∑–∞–π–Ω-—Ä–µ–≤—å—é</b>.\n\n"
        "–ö–∏–¥–∞–π —Å–∫—Ä–∏–Ω –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ ‚Äî —è:\n"
        "1) —Å–∫–∞–∂—É, —á—Ç–æ –≤–∏–∂—É\n"
        "2) —Ä–∞–∑–Ω–µ—Å—É (–∏–ª–∏ –ø–æ—Ö–≤–∞–ª—é) –≤–∏–∑—É–∞–ª\n"
        "3) —Ä–∞–∑–Ω–µ—Å—É (–∏–ª–∏ –ø–æ—Ö–≤–∞–ª—é) —Ç–µ–∫—Å—Ç—ã\n\n"
        "–ñ–º–∏ –∫–Ω–æ–ø–∫—É —Å–Ω–∏–∑—É –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å –∫–∞—Ä—Ç–∏–Ω–∫—É.",
        reply_markup=keyboard,
    )


@dp.message(F.text == BTN_HELP)
async def help_msg(m: Message):
    await m.answer(
        "–ö–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è:\n"
        "‚Ä¢ –û—Ç–ø—Ä–∞–≤—å —Å–∫—Ä–∏–Ω—à–æ—Ç.\n"
        "‚Ä¢ –Ø –ø–æ–∫–∞–∂—É –ø—Ä–æ–≥—Ä–µ—Å—Å ASCII.\n"
        "‚Ä¢ –ü–æ—Ç–æ–º –ø—Ä–∏—à–ª—é 3 —Å–æ–æ–±—â–µ–Ω–∏—è: –æ–ø–∏—Å–∞–Ω–∏–µ / –≤–∏–∑—É–∞–ª / —Ç–µ–∫—Å—Ç—ã.\n\n"
        "–ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –º–µ–ª–∫–∏–π ‚Äî –ø—Ä–∏—à–ª–∏ —Å–∫—Ä–∏–Ω –∫—Ä—É–ø–Ω–µ–µ (–∏–ª–∏ –æ–±—Ä–µ–∂—å –ª–∏—à–Ω–µ–µ) ‚Äî –±—É–¥–µ—Ç —Ç–æ—á–Ω–µ–µ.",
        reply_markup=keyboard,
    )


@dp.message(F.text == BTN_PING)
async def ping(m: Message):
    await m.answer(
        f"pong ‚úÖ\nMODEL: <code>{html_escape(LLM_MODEL)}</code>\nOCR(py): <code>{'on' if OCR_PY_AVAILABLE else 'off'}</code>",
        reply_markup=keyboard,
    )


@dp.message(F.text == BTN_SEND)
async def ask(m: Message):
    await m.answer("–û–∫. –ó–∞–∫–∏–¥—ã–≤–∞–π —Å–∫—Ä–∏–Ω. –ü–æ—Å–º–æ—Ç—Ä—é –∫–∞–∫ —Å–ª–µ–¥—É–µ—Ç.", reply_markup=keyboard)


@dp.message(F.photo)
async def handle_photo(m: Message):
    chat_id = m.chat.id
    lock = get_chat_lock(chat_id)

    if lock.locked():
        await m.answer(
            "‚õî –Ø —É–∂–µ —Ä–∞–∑–±–∏—Ä–∞—é –¥—Ä—É–≥–æ–π —Å–∫—Ä–∏–Ω.\n"
            "–ö–∏–Ω—å —ç—Ç–æ—Ç —á—É—Ç—å –ø–æ–∑–∂–µ, –∏–Ω–∞—á–µ –º—ã —Å–∞–º–∏ —Å–µ–±–µ –≤—Å—ë –ø–µ—Ä–µ–º–µ—à–∞–µ–º.",
            reply_markup=keyboard,
        )
        return

    async with lock:
        # 1) Initial progress (–±–µ–∑ –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã ‚Äî –º–µ–Ω—å—à–µ —à–∞–Ω—Å–æ–≤, —á—Ç–æ Telegram –∑–∞–ø—Ä–µ—Ç–∏—Ç edit)
        progress = await m.answer("‚è≥ –ü—Ä–∏–Ω—è–ª. –ó–∞–≥—Ä—É–∂–∞—é‚Ä¶")
        progress = await animate_progress(progress, title="üîç –°–º–æ—Ç—Ä—é –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ‚Ä¶")

        photo = m.photo[-1]
        file = await bot.get_file(photo.file_id)

        bio = BytesIO()
        await bot.download_file(file.file_path, destination=bio)
        bio.seek(0)

        try:
            img = Image.open(bio).convert("RGBA")
        except Exception:
            await m.answer("‚ö†Ô∏è –ù–µ —Å–º–æ–≥ –æ—Ç–∫—Ä—ã—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É. –ü—Ä–∏—à–ª–∏ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª.", reply_markup=keyboard)
            return

        # 2) Upscale small images (helps both OCR and vision)
        w, h = img.size
        if max(w, h) < 1400:
            img = img.resize((w * 2, h * 2), Image.LANCZOS)

        img_b64 = img_to_base64_png(img)

        # 3) Extract text/structure (OCR first)
        progress = await set_progress(progress, "üßæ –ß–∏—Ç–∞—é —Ç–µ–∫—Å—Ç‚Ä¶", 3)

        extracted = {"ok": False, "text": "", "blocks": []}
        ocr = ocr_extract(img)
        if ocr.get("ok") and (len((ocr.get("text") or "").strip()) >= 12):
            extracted = {"ok": True, "text": ocr.get("text", ""), "blocks": ocr.get("blocks", [])}
        else:
            # LLM extract fallback
            extracted = llm_extract_text_structure(img_b64)
            if not extracted.get("ok"):
                # last resort: keep what OCR gave (even if weak)
                extracted = {"ok": False, "text": ocr.get("text", ""), "blocks": ocr.get("blocks", [])}

        # 4) Review
        progress = await set_progress(progress, "üß† –î—É–º–∞—é‚Ä¶", 5)

        try:
            result = analyze_ui_with_openai(img_b64, extracted)
        except Exception:
            await m.answer(
                "‚ö†Ô∏è –£–ø–∞–ª –Ω–∞ –∞–Ω–∞–ª–∏–∑–µ.\n\n"
                "–°–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ:\n"
                "‚Ä¢ —Å–ª–∏—à–∫–æ–º –º–µ–ª–∫–∏–π —Ç–µ–∫—Å—Ç\n"
                "‚Ä¢ —ç–∫—Ä–∞–Ω –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω\n"
                "‚Ä¢ —á–∞—Å—Ç—å –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –æ–±—Ä–µ–∑–∞–Ω–∞\n\n"
                "–ü–æ–ø—Ä–æ–±—É–π:\n"
                "‚Äî —Å–∫—Ä–∏–Ω –∫—Ä—É–ø–Ω–µ–µ\n"
                "‚Äî –æ–±—Ä–µ–∑–∞—Ç—å –ª–∏—à–Ω–µ–µ –≤–æ–∫—Ä—É–≥\n"
                "‚Äî –Ω–∞ –≤–µ–±–µ: –∑—É–º 125‚Äì150% –∏ –ø–µ—Ä–µ—Å–Ω—è—Ç—å",
                reply_markup=keyboard,
            )
            return

        progress = await set_progress(progress, "‚úÖ –ì–æ—Ç–æ–≤–æ.", 6)

        desc = html_escape(result.get("description", "")) or "‚Äî"
        visual = html_escape(result.get("visual", "")) or "‚Äî"
        text = html_escape(result.get("text", "")) or "‚Äî"
        score = clamp_score(result.get("score", 6))

        # 5) Final 3 messages (+ keyboard again)
        await m.answer(f"üëÄ <b>–ß—Ç–æ —è –≤–∏–∂—É</b>\n{desc}", reply_markup=keyboard)
        await m.answer(f"üéõ <b>–í–∏–∑—É–∞–ª</b> ‚Äî –æ—Ü–µ–Ω–∫–∞: <b>{score}/10</b>\n{visual}", reply_markup=keyboard)
        await m.answer(f"‚úçÔ∏è <b>–¢–µ–∫—Å—Ç—ã</b>\n{text}", reply_markup=keyboard)


@dp.message()
async def fallback(m: Message):
    await m.answer(
        "–Ø –∂–¥—É —Å–∫—Ä–∏–Ω—à–æ—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞.\n"
        "–û—Ç–ø—Ä–∞–≤—å –∫–∞—Ä—Ç–∏–Ω–∫—É ‚Äî –∏ —è —É—Å—Ç—Ä–æ—é —Ä–µ–≤—å—é.",
        reply_markup=keyboard,
    )


async def main():
    print(f"‚úÖ Design Review Partner starting‚Ä¶ model={LLM_MODEL}, OCR_PY={OCR_PY_AVAILABLE}, CV={CV_AVAILABLE}")
    await dp.start_polling(bot)


if __name__ == "__main__":
    asyncio.run(main())
