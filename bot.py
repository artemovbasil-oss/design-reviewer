# bot.py
import os
import re
import json
import base64
import asyncio
from pathlib import Path
from typing import Optional, Tuple

import httpx
from dotenv import load_dotenv

from aiogram import Bot, Dispatcher, F
from aiogram.types import Message, KeyboardButton, ReplyKeyboardMarkup
from aiogram.client.default import DefaultBotProperties

try:
    from PIL import Image
except Exception:
    Image = None

# OCR optional
try:
    import pytesseract
except Exception:
    pytesseract = None


# ---------------------------
# Env / Config
# ---------------------------

def load_env():
    # –í–ê–ñ–ù–û: –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º find_dotenv() (–æ–Ω —É —Ç–µ–±—è –ø–∞–¥–∞–ª AssertionError)
    env_path = Path(__file__).with_name(".env")
    if env_path.exists():
        load_dotenv(dotenv_path=str(env_path), override=False)


def env_bool(key: str, default: bool = False) -> bool:
    v = os.getenv(key, str(default)).strip().lower()
    return v in ("1", "true", "yes", "y", "on")


def env_int(key: str, default: int) -> int:
    try:
        return int(os.getenv(key, str(default)).strip())
    except Exception:
        return default


load_env()

BOT_TOKEN = os.getenv("BOT_TOKEN", "").strip()
if not BOT_TOKEN:
    raise RuntimeError("Set BOT_TOKEN in .env or environment")

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()

LLM_ENABLED = env_bool("LLM_ENABLED", True)
LLM_MODEL = os.getenv("LLM_MODEL", "gpt-4o-mini").strip()

OCR_ENABLED = env_bool("OCR_ENABLED", True)
OCR_LANG = os.getenv("OCR_LANG", "rus+eng").strip()
OCR_MIN_CONF = env_int("OCR_MIN_CONF", 55)

RULES_PATH = os.getenv("RULES_PATH", "rules.json").strip()

# Telegram UI
BTN_SEND_SCREEN = "üñº –ó–∞–∫–∏–Ω—É—Ç—å —Å–∫—Ä–∏–Ω"
BTN_HELP = "‚ÑπÔ∏è –ö–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è"
BTN_PING = "üèì Ping"


# ---------------------------
# Rules loader (optional)
# ---------------------------

def load_rules_text() -> str:
    """
    –ú—ã –Ω–µ –∑–∞—Å—Ç–∞–≤–ª—è–µ–º LLM —Ä–∞–±–æ—Ç–∞—Ç—å —Å—Ç—Ä–æ–≥–æ –ø–æ JSON-—Å—Ç—Ä—É–∫—Ç—É—Ä–µ.
    –ù–æ –¥–∞—ë–º –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –ø—Ä–∞–≤–∏–ª, –µ—Å–ª–∏ rules.json –µ—Å—Ç—å.
    """
    p = Path(__file__).with_name(RULES_PATH)
    if not p.exists():
        return "–ü—Ä–∞–≤–∏–ª–∞: (rules.json –Ω–µ –Ω–∞–π–¥–µ–Ω; —Ä–µ–≤—å—é –¥–µ–ª–∞–µ–º –ø–æ –æ–±—â–∏–º –ø—Ä–∏–Ω—Ü–∏–ø–∞–º –ø–æ–Ω—è—Ç–Ω–æ—Å—Ç–∏ –∏ B2B-—Ç–æ–Ω–∞)."

    try:
        data = json.loads(p.read_text(encoding="utf-8"))
    except Exception:
        return "–ü—Ä–∞–≤–∏–ª–∞: (rules.json –µ—Å—Ç—å, –Ω–æ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å JSON; —Ä–µ–≤—å—é –¥–µ–ª–∞–µ–º –ø–æ –æ–±—â–∏–º –ø—Ä–∏–Ω—Ü–∏–ø–∞–º)."

    # –û–∂–∏–¥–∞–µ–º, —á—Ç–æ —Ç–∞–º –µ—Å—Ç—å —Å–ø–∏—Å–æ–∫ –ø—Ä–∞–≤–∏–ª/–∫–∞—Ç–µ–≥–æ—Ä–∏–π. –ù–æ –Ω–µ –ø—Ä–∏–≤—è–∑—ã–≤–∞–µ–º—Å—è.
    # –°–æ–±–µ—Ä—ë–º –≤ —Ç–µ–∫—Å—Ç: —Å–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã.
    chunks = []
    if isinstance(data, dict):
        if "principles" in data and isinstance(data["principles"], list):
            for x in data["principles"][:20]:
                if isinstance(x, str) and x.strip():
                    chunks.append(f"- {x.strip()}")
        if "rules" in data and isinstance(data["rules"], list):
            for r in data["rules"][:30]:
                if isinstance(r, dict):
                    t = r.get("title") or r.get("name") or r.get("id")
                    d = r.get("description") or r.get("what") or r.get("problem")
                    if t and d:
                        chunks.append(f"- {str(t).strip()}: {str(d).strip()}")
    if not chunks:
        return "–ü—Ä–∞–≤–∏–ª–∞: (rules.json –ø—Ä–æ—á–∏—Ç–∞–Ω, –Ω–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è; —Ä–µ–≤—å—é –¥–µ–ª–∞–µ–º –ø–æ –æ–±—â–∏–º –ø—Ä–∏–Ω—Ü–∏–ø–∞–º + –∑–¥—Ä–∞–≤–æ–º—É —Å–º—ã—Å–ª—É)."

    return "–ö–æ—Ä–æ—Ç–∫–æ –æ –ø—Ä–∞–≤–∏–ª–∞—Ö/–ø—Ä–∏–Ω—Ü–∏–ø–∞—Ö:\n" + "\n".join(chunks)


RULES_TEXT = load_rules_text()


# ---------------------------
# Helpers
# ---------------------------

def ascii_progress_frame(step: int, total: int = 10, label: str = "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é") -> str:
    filled = max(0, min(total, step))
    bar = "#" * filled + "-" * (total - filled)
    # —á—É—Ç—å –±–æ–ª—å—à–µ ASCII-–≤–∞–π–±–∞
    return (
        f"{label}...\n"
        f"[{bar}] {filled}/{total}\n"
        f"‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n"
        f"‚îÇ   {('‚ñ∞' * filled).ljust(total)}   ‚îÇ\n"
        f"‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ"
    )


def clean_text(s: str) -> str:
    # —á–∏—Å—Ç–∏–º —Å—Ç—Ä–∞–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã/–º—É—Å–æ—Ä
    s = s.replace("\u00a0", " ")
    s = re.sub(r"[ \t]+", " ", s)
    s = re.sub(r"\n{3,}", "\n\n", s)
    return s.strip()


def score_clamp(x: int) -> int:
    return max(1, min(10, x))


def guess_font_family_from_image_text(ocr_text: str) -> str:
    # –ú—ã —á–µ—Å—Ç–Ω–æ "—É–≥–∞–¥—ã–≤–∞–µ–º". –ë–µ–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –∏ —Ä–∞–∑–º–µ—Ä–æ–≤.
    # –ù–∞ –¥–µ–ª–µ —à—Ä–∏—Ñ—Ç –ø–æ OCR –ø–æ—á—Ç–∏ –Ω–µ –≤—ã—Ç–∞—â–∏—Ç—å; –¥–µ–ª–∞–µ–º –º—è–≥–∫–∏–π –≤—ã–≤–æ–¥.
    if not ocr_text:
        return "–ù–µ —É–≤–µ—Ä–µ–Ω (–º–∞–ª–æ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —É–≥–∞–¥—ã–≤–∞–Ω–∏—è)"
    # –ø—Ä–æ—Å—Ç–æ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞
    return "–ü–æ—Ö–æ–∂–µ –Ω–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π sans-serif (—Ç–∏–ø–∞ Inter / SF / Roboto) ‚Äî –±–µ–∑ –≥–∞—Ä–∞–Ω—Ç–∏–π"


def ocr_extract_text(image_path: str) -> str:
    if not OCR_ENABLED:
        return ""
    if pytesseract is None or Image is None:
        return ""
    try:
        img = Image.open(image_path)
        # tesseract –∫–æ–Ω—Ñ–∏–≥: —Ç–∞–±—ã/–ø—Ä–æ–±–µ–ª—ã, –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º
        data = pytesseract.image_to_data(img, lang=OCR_LANG, output_type=pytesseract.Output.DICT)
        words = []
        n = len(data.get("text", []))
        for i in range(n):
            txt = (data["text"][i] or "").strip()
            conf = data.get("conf", [])[i]
            try:
                conf_i = int(float(conf))
            except Exception:
                conf_i = -1
            if txt and conf_i >= OCR_MIN_CONF:
                words.append(txt)
        return clean_text(" ".join(words))
    except Exception:
        return ""


async def call_openai_vision_review(
    image_bytes: bytes,
    ocr_text: str,
    rules_text: str,
    model: str,
) -> Tuple[str, str, str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç 3 —Ç–µ–∫—Å—Ç–∞: (—á—Ç–æ –≤–∏–∂—É), (–≤–∏–∑—É–∞–ª), (—Ç–µ–∫—Å—Ç).
    –ë–µ–∑ JSON, —á—Ç–æ–±—ã –Ω–µ –ª–æ–≤–∏—Ç—å "invalid JSON" –∏ –æ—à–∏–±–∫–∏ —Ñ–æ—Ä–º–∞—Ç–∞.
    """
    if not OPENAI_API_KEY:
        raise RuntimeError("OPENAI_API_KEY is not set")

    b64 = base64.b64encode(image_bytes).decode("utf-8")
    data_url = f"data:image/png;base64,{b64}"

    # –ñ—ë—Å—Ç–∫–æ –∑–∞–¥–∞—ë–º —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: 3 —Å–µ–∫—Ü–∏–∏ –ø—Ä–æ—Å—Ç—ã–º —Ç–µ–∫—Å—Ç–æ–º.
    system = (
        "–¢—ã ‚Äî –ø—Ä–∏–¥–∏—Ä—á–∏–≤—ã–π —Å—Ç–∞—Ä—à–∏–π –¥–∏–∑–∞–π–Ω-—Ä–µ–≤—å—é–µ—Ä –¥–ª—è B2B –±–∞–Ω–∫–∞. "
        "–¢—ã —á–µ—Å—Ç–Ω—ã–π, –∏–Ω–æ–≥–¥–∞ –∂—ë—Å—Ç–∫–∏–π, –Ω–æ –±–µ–∑ –≥—Ä—É–±–æ—Å—Ç–∏ –∏ –±–µ–∑ –º–∞—Ç–∞. "
        "–ï—Å–ª–∏ —Ö–æ—Ä–æ—à–æ ‚Äî –ø–æ—Ö–≤–∞–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ. –ï—Å–ª–∏ –ø–ª–æ—Ö–æ ‚Äî —Ä—É–≥–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ. "
        "–ù–ï –∏—Å–ø–æ–ª—å–∑—É–π HTML-—Ç–µ–≥–∏. –ù–∏–∫–∞–∫–∏—Ö JSON, –Ω–∏–∫–∞–∫–∏—Ö —Å–ª–æ–≤–∞—Ä–µ–π –≤–∏–¥–∞ {'key': ...}."
    )

    user = (
        "–ó–∞–¥–∞—á–∞: –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–∫—Ä–∏–Ω –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞.\n\n"
        "–í—ã—Ö–æ–¥: –≤–µ—Ä–Ω–∏ –†–û–í–ù–û —Ç—Ä–∏ –±–ª–æ–∫–∞ —Ç–µ–∫—Å—Ç–∞, –≤ —Ç–∞–∫–æ–º —Ñ–æ—Ä–º–∞—Ç–µ:\n"
        "1) WHAT_I_SEE: 2‚Äì6 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, —á—Ç–æ –Ω–∞ —ç–∫—Ä–∞–Ω–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç.\n"
        "2) VISUAL_REVIEW (SCORE X/10): 5‚Äì12 –ø—É–Ω–∫—Ç–æ–≤. –¢–æ–ª—å–∫–æ –ø—Ä–æ –≤–∏–∑—É–∞–ª/UX: –∏–µ—Ä–∞—Ä—Ö–∏—è, –æ—Ç—Å—Ç—É–ø—ã, –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ, –ø–µ—Ä–µ–≥—Ä—É–∑, –∫–æ–Ω—Ç—Ä–∞—Å—Ç (–±–µ–∑ —á–∏—Å–µ–ª), –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å, —á–∏—Ç–∞–µ–º–æ—Å—Ç—å. "
        "–ü—Ä–æ —à—Ä–∏—Ñ—Ç ‚Äî –¢–û–õ–¨–ö–û –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–µ –æ —Å–µ–º–µ–π—Å—Ç–≤–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä 'sans-serif —Ç–∏–ø–∞ Inter/SF/Roboto'), –±–µ–∑ —Ä–∞–∑–º–µ—Ä–æ–≤, –º–µ–¥–∏–∞–Ω –∏ —Ç–æ—á–Ω—ã—Ö —Ü–≤–µ—Ç–æ–≤.\n"
        "3) TEXT_REVIEW (SCORE Y/10): 6‚Äì14 –ø—É–Ω–∫—Ç–æ–≤. –ö–∞–∂–¥—ã–π –ø—É–Ω–∫—Ç: '–ü—Ä–æ–±–ª–µ–º–∞ ‚Üí –ü–æ—á–µ–º—É –ø–ª–æ—Ö–æ ‚Üí –ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å'. "
        "–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —á—Ç–æ–±—ã –±—ã–ª–æ –ø–æ–Ω—è—Ç–Ω–æ, —á—Ç–æ –∏–º–µ–Ω–Ω–æ –Ω–µ —Ç–∞–∫ –∏ —á—Ç–æ —Å–¥–µ–ª–∞—Ç—å.\n\n"
        "–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–∞–≤–∏–ª (—Å—É—Ç—å):\n"
        f"{rules_text}\n\n"
        "–ï—Å–ª–∏ OCR —Ç–µ–∫—Å—Ç –µ—Å—Ç—å ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ –∫–∞–∫ –ø–æ–¥—Å–∫–∞–∑–∫—É, –Ω–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç —É —Ç–æ–≥–æ, —á—Ç–æ –≤–∏–¥–Ω–æ –Ω–∞ —ç–∫—Ä–∞–Ω–µ.\n"
        f"OCR_TEXT (–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–ø–æ–ª–Ω—ã–π): {ocr_text or '(–Ω–µ—Ç)'}\n"
    )

    payload = {
        "model": model,
        "input": [
            {
                "role": "system",
                "content": [{"type": "input_text", "text": system}],
            },
            {
                "role": "user",
                "content": [
                    {"type": "input_text", "text": user},
                    {"type": "input_image", "image_url": data_url},
                ],
            },
        ],
        "max_output_tokens": 900,
    }

    url = "https://api.openai.com/v1/responses"
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json",
    }

    async with httpx.AsyncClient(timeout=90) as client:
        r = await client.post(url, headers=headers, json=payload)
        r.raise_for_status()
        out = r.json()

    # –≤—ã—Ç–∞—Å–∫–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ Responses API
    text_parts = []
    for item in out.get("output", []):
        for c in item.get("content", []):
            if c.get("type") == "output_text" and c.get("text"):
                text_parts.append(c["text"])
    full = clean_text("\n".join(text_parts))
    if not full:
        raise RuntimeError("LLM returned empty output")

    # –ø–∞—Ä—Å–∏–º 3 —Å–µ–∫—Ü–∏–∏ –ø–æ –º–∞—Ä–∫–µ—Ä–∞–º
    # (–¥–µ–ª–∞–µ–º —É—Å—Ç–æ–π—á–∏–≤–æ: –¥–∞–∂–µ –µ—Å–ª–∏ –º–æ–¥–µ–ª—å —á—É—Ç—å –æ—Ç–∫–ª–æ–Ω–∏—Ç—Å—è, –º—ã –≤—ã—Ç–∞—â–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ)
    what = ""
    visual = ""
    text = ""

    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
    norm = full.replace("\r\n", "\n")

    def extract_block(marker: str) -> str:
        m = re.search(rf"{marker}\s*:\s*", norm, flags=re.IGNORECASE)
        if not m:
            return ""
        start = m.end()
        # –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –º–∞—Ä–∫–µ—Ä–∞ –∏–ª–∏ –∫–æ–Ω–µ—Ü
        next_m = re.search(r"(WHAT_I_SEE\s*:|VISUAL_REVIEW\s*\(|TEXT_REVIEW\s*\()", norm[start:], flags=re.IGNORECASE)
        if next_m:
            return clean_text(norm[start:start + next_m.start()])
        return clean_text(norm[start:])

    what = extract_block("WHAT_I_SEE")
    # –¥–ª—è VISUAL/TEXT —É–¥–æ–±–Ω–µ–µ –≤—ã—Ä–µ–∑–∞—Ç—å –ø–æ —Å—Ç—Ä–æ–∫–∞–º
    # –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Å–µ–∫—Ü–∏–∏ —á–µ—Ä–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∏
    vm = re.search(r"VISUAL_REVIEW\s*\(.*?\)\s*:", norm, flags=re.IGNORECASE)
    tm = re.search(r"TEXT_REVIEW\s*\(.*?\)\s*:", norm, flags=re.IGNORECASE)

    if vm:
        start = vm.end()
        end = tm.start() if tm else len(norm)
        visual = clean_text(norm[start:end])

    if tm:
        start = tm.end()
        text = clean_text(norm[start:])

    # fallback: –µ—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –Ω–µ —Å–æ–±–ª—é–¥—ë–Ω, –ø—Ä–æ—Å—Ç–æ —Ä–∞–∑—Ä–µ–∂–µ–º –∞–∫–∫—É—Ä–∞—Ç–Ω–æ
    if not (what and visual and text):
        # –ø–æ–ø—Ä–æ–±—É–µ–º –≥—Ä—É–±–æ –ø–æ–¥–µ–ª–∏—Ç—å –Ω–∞ 3 —á–∞—Å—Ç–∏ –ø–æ –ø—É—Å—Ç—ã–º —Å—Ç—Ä–æ–∫–∞–º
        parts = [p.strip() for p in re.split(r"\n\s*\n", norm) if p.strip()]
        if not what and parts:
            what = parts[0]
        if not visual and len(parts) >= 2:
            visual = parts[1]
        if not text and len(parts) >= 3:
            text = "\n\n".join(parts[2:])

    return what.strip(), visual.strip(), text.strip()


# ---------------------------
# Telegram bot setup
# ---------------------------

kb = ReplyKeyboardMarkup(
    keyboard=[
        [KeyboardButton(text=BTN_SEND_SCREEN)],
        [KeyboardButton(text=BTN_HELP), KeyboardButton(text=BTN_PING)],
    ],
    resize_keyboard=True,
    input_field_placeholder="–ö–∏–¥–∞–π —Å–∫—Ä–∏–Ω ‚Äî —è —Ä–∞–∑–Ω–µ—Å—É (–ø–æ –¥–µ–ª—É).",
)

bot = Bot(
    token=BOT_TOKEN,
    default=DefaultBotProperties(parse_mode=None),  # –±–µ–∑ HTML, —á—Ç–æ–±—ã –Ω–µ –ª–æ–≤–∏—Ç—å entity errors
)
dp = Dispatcher()


@dp.message(F.text.in_({"/start", "start"}))
async def cmd_start(m: Message):
    await m.answer(
        "–Ø ‚Äî –ø–∞—Ä—Ç–Ω—ë—Ä –ø–æ –¥–∏–∑–∞–π–Ω-—Ä–µ–≤—å—é.\n"
        "–ö–∏–¥–∞–π —Å–∫—Ä–∏–Ω –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ ‚Äî —è –ø—Ä–∏–¥–∏—Ä—á–∏–≤–æ —Ä–∞–∑–±–µ—Ä—É UI/UX –∏ —Ç–µ–∫—Å—Ç—ã.\n\n"
        "–ñ–º–∏ ¬´üñº –ó–∞–∫–∏–Ω—É—Ç—å —Å–∫—Ä–∏–Ω¬ª –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å –∫–∞—Ä—Ç–∏–Ω–∫—É —Å—é–¥–∞.",
        reply_markup=kb,
    )


@dp.message(F.text == BTN_HELP)
async def cmd_help(m: Message):
    await m.answer(
        "–ö–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è:\n"
        "1) –û—Ç–ø—Ä–∞–≤—å —Å–∫—Ä–∏–Ω –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞.\n"
        "2) –Ø –ø–æ–∫–∞–∂—É –ø—Ä–æ–≥—Ä–µ—Å—Å ASCII.\n"
        "3) –ü–æ—Ç–æ–º –ø—Ä–∏—à–ª—é 3 —Å–æ–æ–±—â–µ–Ω–∏—è:\n"
        "   ‚Ä¢ —á—Ç–æ –≤–∏–∂—É –Ω–∞ —ç–∫—Ä–∞–Ω–µ\n"
        "   ‚Ä¢ –≤–∏–∑—É–∞–ª—å–Ω—ã–π —Ä–∞–∑–±–æ—Ä + –æ—Ü–µ–Ω–∫–∞\n"
        "   ‚Ä¢ —Ä–∞–∑–±–æ—Ä —Ç–µ–∫—Å—Ç–∞ + –æ—Ü–µ–Ω–∫–∞\n\n"
        "–ü–æ–¥—Å–∫–∞–∑–∫–∞: —á–µ–º –∫—Ä—É–ø–Ω–µ–µ —Ç–µ–∫—Å—Ç –Ω–∞ —Å–∫—Ä–∏–Ω–µ ‚Äî —Ç–µ–º —Ç–æ—á–Ω–µ–µ –ø—Ä–∏–¥–∏—Ä–∫–∏.",
        reply_markup=kb,
    )


@dp.message(F.text == BTN_PING)
async def cmd_ping(m: Message):
    await m.answer(
        f"pong ‚úÖ\n"
        f"LLM_ENABLED={LLM_ENABLED}\n"
        f"MODEL={LLM_MODEL}\n"
        f"OCR_ENABLED={OCR_ENABLED} ({OCR_LANG})\n"
        f"RULES={RULES_PATH}",
        reply_markup=kb,
    )


@dp.message(F.text == BTN_SEND_SCREEN)
async def ask_screen(m: Message):
    await m.answer("–û–∫. –ö–∏–¥–∞–π —Å–∫—Ä–∏–Ω—à–æ—Ç. –Ø –ø–æ—Å–º–æ—Ç—Ä—é –∏ –¥–æ–∫–æ–ø–∞—é—Å—å –ø–æ –¥–µ–ª—É üôÇ", reply_markup=kb)


@dp.message(F.photo)
async def handle_photo(m: Message):
    # —Å–∫–∞—á–∏–≤–∞–µ–º —Ñ–æ—Ç–æ (–±–µ—Ä—ë–º —Å–∞–º–æ–µ –±–æ–ª—å—à–æ–µ)
    photo = m.photo[-1]
    file = await bot.get_file(photo.file_id)
    # –≤—Ä–µ–º–µ–Ω–Ω—ã–π –ø—É—Ç—å
    tmp_dir = Path("/tmp")
    tmp_dir.mkdir(parents=True, exist_ok=True)
    img_path = tmp_dir / f"tg_{photo.file_unique_id}.png"
    await bot.download_file(file.file_path, destination=str(img_path))

    # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä ASCII (—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ)
    progress_msg = await m.answer(ascii_progress_frame(1, label="–ó–∞–≥—Ä—É–∂–∞—é"), reply_markup=kb)

    # —á–∏—Ç–∞–µ–º –±–∞–π—Ç—ã
    image_bytes = img_path.read_bytes()

    # OCR (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    await progress_msg.edit_text(ascii_progress_frame(3, label="–î–æ—Å—Ç–∞—é —Ç–µ–∫—Å—Ç (OCR)"))
    ocr_text = ocr_extract_text(str(img_path))

    # –£–≥–∞–¥–∞–µ–º ‚Äú—Å–µ–º–µ–π—Å—Ç–≤–æ —à—Ä–∏—Ñ—Ç–∞‚Äù –æ—á–µ–Ω—å –º—è–≥–∫–æ (–∏ —á–µ—Å—Ç–Ω–æ)
    font_guess = guess_font_family_from_image_text(ocr_text)

    # LLM review
    if not LLM_ENABLED:
        await progress_msg.edit_text(ascii_progress_frame(10, label="–ì–æ—Ç–æ–≤–æ"))
        await m.answer(
            "LLM –≤—ã–∫–ª—é—á–µ–Ω (LLM_ENABLED=false).\n"
            "–Ø —Å–µ–π—á–∞—Å –º–æ–≥—É —Å–¥–µ–ª–∞—Ç—å —Ç–æ–ª—å–∫–æ OCR-—Å–≤–æ–¥–∫—É.\n\n"
            f"–¢–µ–∫—Å—Ç (OCR): {ocr_text or '(–Ω–µ –∏–∑–≤–ª—ë–∫)'}\n"
            f"–®—Ä–∏—Ñ—Ç (–ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–µ): {font_guess}",
            reply_markup=kb,
        )
        return

    await progress_msg.edit_text(ascii_progress_frame(5, label="–î—É–º–∞—é (LLM)"))

    try:
        what, visual, text = await call_openai_vision_review(
            image_bytes=image_bytes,
            ocr_text=ocr_text,
            rules_text=RULES_TEXT,
            model=LLM_MODEL,
        )
    except httpx.HTTPStatusError as e:
        await progress_msg.edit_text(ascii_progress_frame(10, label="–£–ø—Å"))
        await m.answer(
            f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM: {e.response.status_code}\n"
            f"{clean_text(e.response.text)[:1200]}",
            reply_markup=kb,
        )
        return
    except Exception as e:
        await progress_msg.edit_text(ascii_progress_frame(10, label="–£–ø—Å"))
        await m.answer(f"‚ö†Ô∏è –£–ø–∞–ª–æ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}", reply_markup=kb)
        return

    await progress_msg.edit_text(ascii_progress_frame(10, label="–ì–æ—Ç–æ–≤–æ"))

    # 1) —á—Ç–æ –≤–∏–∂—É
    await m.answer(
        "üëÄ –ß—Ç–æ —è –≤–∏–∂—É –Ω–∞ —Å–∫—Ä–∏–Ω–µ:\n"
        f"{what}\n\n"
        f"–®—Ä–∏—Ñ—Ç (–ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–µ): {font_guess}",
        reply_markup=kb,
    )

    # 2) –≤–∏–∑—É–∞–ª
    await m.answer(
        "üéõ –í–∏–∑—É–∞–ª—å–Ω—ã–π —Ä–∞–∑–±–æ—Ä:\n"
        f"{visual}",
        reply_markup=kb,
    )

    # 3) —Ç–µ–∫—Å—Ç
    await m.answer(
        "‚úçÔ∏è –†–∞–∑–±–æ—Ä —Ç–µ–∫—Å—Ç–∞:\n"
        f"{text}",
        reply_markup=kb,
    )


@dp.message()
async def fallback(m: Message):
    await m.answer(
        "–Ø –ø–æ–Ω–∏–º–∞—é –ª–∏–±–æ –∫–æ–º–∞–Ω–¥—ã, –ª–∏–±–æ –∫–∞—Ä—Ç–∏–Ω–∫—É.\n"
        "–ö–∏–¥–∞–π —Å–∫—Ä–∏–Ω—à–æ—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ ‚Äî –∏ —è —É—Å—Ç—Ä–æ—é —Ä–µ–≤—å—é.",
        reply_markup=kb,
    )


async def main():
    print(f"‚úÖ Bot starting‚Ä¶ LLM_ENABLED={LLM_ENABLED}, model={LLM_MODEL}, OCR_ENABLED={OCR_ENABLED}, rules={RULES_PATH}")
    await dp.start_polling(bot)


if __name__ == "__main__":
    asyncio.run(main())
